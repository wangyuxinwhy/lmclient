---
sidebar_position: 1
---

# å¿«é€Ÿå¼€å§‹

## ç®€ä»‹

LMClient è®©ä½ ç”¨æœ€ç®€å•çš„æ–¹å¼è°ƒç”¨æœ€å¼ºå¤§çš„è¯­è¨€æ¨¡å‹ï¼

LMClient ç»Ÿä¸€äº†ä¸åŒå¹³å°çš„æ¶ˆæ¯æ ¼å¼ï¼Œæ¨ç†å‚æ•°ï¼Œæ¥å£å°è£…ï¼Œè¿”å›è§£æã€‚æä¾›æµå¼ï¼Œéæµå¼ï¼ŒåŒæ­¥ï¼Œå¼‚æ­¥å¤šç§è°ƒç”¨æ–¹å¼ï¼Œæ”¯æŒè¾“å…¥æ£€æŸ¥ï¼Œå‚æ•°æ£€æŸ¥ï¼Œæ·»åŠ äº† *ChatEngine*, *CompletionEngine*, *function* ç­‰å¤šç§è¾…åŠ©åŠŸèƒ½...

ç›®å‰å·²æ”¯æŒï¼š[OpenAI](https://openai.com/) | [Azure](https://azure.microsoft.com/) | [Minimax](https://api.minimax.chat/) | [ç™¾åº¦æ–‡å¿ƒ](https://cloud.baidu.com/product/wenxinworkshop) | [ç™¾å·](https://platform.baichuan-ai.com/docs/api) | [æ™ºè°±](https://www.zhipuai.cn/) | [è…¾è®¯æ··å…ƒ](https://cloud.tencent.com/product/hunyuan)


## åŸºç¡€ä½¿ç”¨
open in colab
### å®‰è£…
```bash
pip install lmclient-core
```

### åˆå§‹åŒ–æ¨¡å‹

```python
from lmclient import OpenAIChat


gpt35 = OpenAIChat(api_key='<your openai api key>')
# gpt4 = OpenAIChat(model='gpt-4')
model_response = gpt35.chat_completion('ä½ å¥½')
```

å½“ä½ æ²¡æœ‰æŒ‡å®š api_key æ—¶ï¼ŒLMClient ä¼šå°è¯•ä»ç¯å¢ƒå˜é‡ä¸­å¯¼å…¥ã€‚

é™¤äº†æ˜¾å¼çš„å¼•å…¥ `OpenAIChat` ç±»å¤–ï¼Œæ‚¨è¿˜å¯ä»¥é€šè¿‡ model_id æ¥åˆå§‹åŒ–æ¨¡å‹ï¼Œè¯¦æƒ…å‚è€ƒ [æ¨¡å‹åˆ—è¡¨](./model_list.md)

```python
from lmclient import load_from_model_id

model = load_from_model_id('openai/gpt-4')
model_response = model.chat_completion('ä½ å¥½')
```

### ä¿®æ”¹æ¨ç†å‚æ•°

- åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶ï¼Œè®¾ç½®é»˜è®¤çš„æ¨ç†å‚æ•°

```python
from lmclient import OpenAIChat, OpenAIChatParameters

model = OpenAIChat(api_key='<your openai api key>', parameters=OpenAIChatParameters(temperature=0))
model_response = model.chat_completion('ä½ å¥½')
```

- åœ¨æ–¹æ³•è°ƒç”¨æ—¶ï¼Œè®¾ç½®åŠ¨æ€çš„æ¨ç†å‚æ•°

```python
model_response = model.chat_completion('ä½ å¥½', temperature=0)
```

### æµå¼æ¨ç†

ä½¿ç”¨ `stream_chat_completion` æ–¹æ³•è¿›è¡Œæµå¼æ¨ç†

```python
for stream_response in model.stream_chat_completion('ä½ å¥½'):
    print(stream_response.stream.delta, end='', flush=True)
    if stream_response.is_finish:
        response = stream_response
```

æ­¤å¤–ï¼ŒLMClient è¿˜æ”¯æŒå¼‚æ­¥æ¨ç†å’Œå¼‚æ­¥æµå¼æ¨ç†ï¼Œè¯¦æƒ…å‚è€ƒ [è¿›é˜¶ä½¿ç”¨](./advanced_usage.md)


### ChatEngine èŠå¤©å¼•æ“

`chat_completion` æ–¹æ³•æ˜¯æ— çŠ¶æ€çš„ï¼Œå³æ¯æ¬¡è°ƒç”¨éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œä¸ä¼šè®°ä½ä¸Šä¸€æ¬¡çš„å¯¹è¯å†…å®¹ã€‚

ChatEngine èŠå¤©å¼•æ“ï¼Œä¸ºäº†èŠå¤©åœºæ™¯è€Œè®¾è®¡ï¼Œæ·»åŠ äº†å¯¹è¯å†å²ç®¡ç†ï¼Œå¤„ç† *function call* ï¼Œæµå¼æ‰“å°ç­‰åŠŸèƒ½

```python
from lmclient import MinimaxChat, ChatEngine, function


bot = ChatEngine(MinimaxChat())
bot.chat('ä½ å¥½ï¼Œæˆ‘å« lmclient')
bot.chat('æˆ‘æ˜¯è°ï¼Ÿ')
```

è¾“å‡º

```
user: ä½ å¥½ï¼Œæˆ‘å« lmclient
assistant: ä½ å¥½ï¼Œlmclientï¼Œæˆ‘æ˜¯MMæ™ºèƒ½åŠ©ç†ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼
user: æˆ‘æ˜¯è°ï¼Ÿ
assistant: ä½ æ˜¯lmclientï¼Œä¸€ä¸ªç”±MiniMaxè‡ªç ”çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚
```

### CompletionEngine è¡¥å…¨å¼•æ“

CompletionEngine è¡¥å…¨å¼•æ“ï¼Œä¸ºæ‰¹é‡ç”Ÿæˆæˆ–è¡¥å…¨ä»»åŠ¡è€Œè®¾è®¡ï¼Œåœ¨ `chat_completion` çš„åŠŸèƒ½ä¹‹ä¸Šï¼Œæ·»åŠ äº†å¼‚æ­¥å¹¶å‘æ§åˆ¶ï¼Œæ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ§åˆ¶ï¼Œè¿›åº¦æ¡ç­‰åŠŸèƒ½ã€‚

- `run` æ–¹æ³•åŒæ­¥æ‰¹é‡è¿è¡Œ
- `async_run` æ–¹æ³•å¼‚æ­¥æ‰¹é‡è¿è¡Œ

```python
import asyncio

from lmclient import CompletionEngine, MinimaxChat

async def main():
    model = MinimaxChat()
    # æ§åˆ¶æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ¬¡æ•°ä¸º 20ï¼Œ å¼‚æ­¥å¹¶å‘ä¸º 5
    completion_engine = CompletionEngine(model, async_capacity=5, max_requests_per_minute=20)
    prompts = [
        'Hello, my name is',
        'can you please tell me your name?',
        'what is your name?',
    ]
    async for response in completion_engine.async_run(prompts=prompts):
        print(response.reply)

asyncio.run(main())
```

### function call å‡½æ•°è°ƒç”¨

LMClient æä¾›äº† function call çš„é›†æˆï¼Œå¹¶æä¾›äº† `@function` è£…é¥°å™¨ï¼Œç»è¿‡è£…é¥°çš„ Python å‡½æ•°å¯ä»¥è‡ªåŠ¨çš„ç”Ÿæˆ jsonschema ï¼Œè¿›è€Œå¸®åŠ©ç®€åŒ– function call å·¥ä½œæµã€‚


```python
from lmclient import OpenAIChat, ChatEngine, function

@function
def get_weather(city: str) -> str:
    """Get weather of the city."""
    return f'{city}å¤©æ°”æ™´æœ—, æ°”æ¸©20åº¦'

bot = ChatEngine(OpenAIChat(), functions=[get_weather])
bot.chat('ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ')
```

è¾“å‡º

```
user: ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ
Function call: get_weather
Arguments: {
    "city": "åŒ—äº¬"
}
function: "åŒ—äº¬å¤©æ°”æ™´æœ—, æ°”æ¸©20åº¦"
assistant: ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©20åº¦ã€‚
```

:::warning
ä¸æ˜¯æ‰€æœ‰å¹³å°çš„æ¨¡å‹éƒ½æ”¯æŒ function callï¼Œç›®å‰åªæœ‰ ç™¾åº¦æ–‡å¿ƒï¼ŒMinimaxProï¼Œ OpenAI æ”¯æŒ
:::


### å¤šæ¨¡å‹è°ƒç”¨

åªè°ƒç”¨ä¸€ä¸ªæ¨¡å‹æ˜¾ç¤ºä¸å‡ºç»Ÿä¸€æ¥å£çš„é­…åŠ›ï¼Œæˆ‘ä»¬æ¥è°ƒç”¨å¤šä¸ªæ¨¡å‹ï¼Œçœ‹çœ‹ LMClient æ˜¯å¦‚ä½•ç»Ÿä¸€ä¸åŒå¹³å°çš„æ¥å£çš„ã€‚

```python
from lmclient import MinimaxChat, MinimaxProChat, OpenAIChat, WenxinChat, ZhiPuChat, HunyuanChat, BaichuanChat, ZhiPuCharacterChat

chat_models = [
    MinimaxChat(),
    MinimaxProChat(),
    OpenAIChat(),
    WenxinChat(),
    ZhiPuChat(),
    ZhiPuCharacterChat(),
    HunyuanChat(),
    BaichuanChat(),
]

for model in chat_models:
    model_response = model.chat_completion('ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±', temperature=0)
    print(f'{model.model_id}: {model_response.reply}')
```

è¾“å‡º

```
minimax/abab5.5-chat: ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
minimax_pro/abab5.5-chat: ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
openai/gpt-3.5-turbo: ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
wenxin/ERNIE-Bot: ä½ å¥½ï¼Œå¾ˆé«˜å…´å’Œä½ äº¤æµã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
zhipu/chatglm_turbo: " ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼Œå¯ä»¥å«æˆ‘å°æ™ºğŸ¤–ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"
zhipu-character/characterglm: "ï¼ˆæœ‰ç‚¹å°´å°¬ï¼‰ä½ å¥½ï¼Œä¸å¥½æ„æ€ï¼Œæˆ‘å¥½åƒèµ°é”™åŒ–å¦†é—´äº†\n"
hunyuan/v1: ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ
zhipu/Baichuan2-53B: ä½ å¥½ï¼å¾ˆé«˜å…´å’Œä½ äº¤æµã€‚è¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘å¯ä»¥å¸®åŠ©ä½ è§£å†³å—ï¼Ÿ
```

## ä¹‹åå‘¢ï¼Ÿ

- å¦‚æœä½ å¯¹ LMClient æ”¯æŒçš„æ¨¡å‹æ„Ÿå…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹ [æ¨¡å‹åˆ—è¡¨](./model_list.md)
- å¦‚æœä½ å¯¹ ChatEngineï¼ŒCompletionEngineï¼Œfunction call ç­‰åŠŸèƒ½æ„Ÿå…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹ [è¿›é˜¶ä½¿ç”¨](./advanced_usage.md)
- å¦‚æœä½ å¯¹ LMClient çš„è¯ç”Ÿï¼Œè®¾è®¡ä»¥åŠæ„¿æ™¯æ„Ÿå…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹ [LMClient Blog](/blog)